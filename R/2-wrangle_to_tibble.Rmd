---
title: "Read and combine .nc files"
author: "Eric R. Scott"
date: "2021-11-10"
output: 
  html_document: 
    toc: yes
    toc_float: yes
    number_sections: yes
    highlight: kate
    theme:
      version: 4
      bootswatch: flatly

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, paged.print=FALSE)
library(tidyverse)
library(here)
library(conflicted)
library(stars)

conflict_prefer("lag", "dplyr")
conflict_prefer("filter", "dplyr")
```

*Last compiled: `r Sys.Date()`*

# Purpose

For each CMIP6 model, I want a tibble with a single value for each climate variable for each month. These values should be an average of a 3x3 grid cell area with my study site (Biological Dynamics of Forest Fragments Project, BDFFP) roughly at its center.

The center of BDFFP is at about -2.41ºN, -59.83ºE


# Read in files

`read_stars()` automatically combines .nc files with the same dimensions.

```{r}
files <- list.files(here("data_raw", "ssp126", "MRI-ESM2-0"), full.names = TRUE)
x <- read_stars(files, proxy = TRUE) 
#proxy = TRUE means it only reads metadata.  Doesn't read in files until calculations are performed.

#set coordinate reference system?  CMIP documentation say it's WGS84
#From James Michielini:
st_crs(x) <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"

x
```

So, there's a bunch of warnings from GDAL, but I don't know what they mean. 

# Fix the variable names

For some reason the variable names are the file names??  I'll just extract the first part, which is the variable.

```{r}
names(x) <- str_extract(names(x), "^[:alpha:]+(?=_)")
```

# Crop

I'm trying to understand WHY the dimensions are like they are.

```{r}
st_dimensions(x)
st_get_dimension_values(x, which = "x", where = "center") %>% max()
st_get_dimension_values(x, which = "x", where = "start") %>% max()
st_get_dimension_values(x, which = "x", where = "end") %>% max()

359.4375 + 0.5625
```

Ok, so first pixel is *centered* at 0, so last pixel ends where first pixel begins (-0.5626 = 359.4375), and that does total 360º, even though the "last" pixel actually ends at 359.4375.

Is it worthwhile to try to change the coordinates to just normal decimal degrees or whatever?  -59.83ºE is just 360-59.83 = 300.17, yeah?  Or is it 358.875 - 59.83?

## What pixel contains the center of BDFFP?

So, I'm sure there is a "spatial stats" way to do this by, like, creating a `sf` object of a point, and then asking where that point intersects my raster, but I'm going to do this the dumb way for now.

```{r}
lon_pixels_cen <- st_get_dimension_values(x, which = "x", where = "center")
lon_pixels_start <- st_get_dimension_values(x, which = "x", where = "start")
lon_pixels_end <- st_get_dimension_values(x, which = "x", where = "end")
# using the start of the pixels because I don't know why.  I did some trial and error stuff and this worked?
lon_dist <- lon_pixels_start - (359.4375-59.83) 
which.min(abs(lon_dist))
# pixel 268 in the lon dimension contains BDFFP
lon_pixels_start[which.min(abs(lon_dist))] - 359.4375
lon_pixels_end[which.min(abs(lon_dist))] -359.4375
```

```{r}
lat_pixels_cen <- st_get_dimension_values(x, which = "y", where = "center")
lat_pixels_start <- st_get_dimension_values(x, which = "y", where = "start")
lat_pixels_end <- st_get_dimension_values(x, which = "y", where = "end")
lat_dist <- lat_pixels_start - (-2.41) 
which.min(abs(lat_dist)) 
# pixel 83 in the lat dimension
lat_pixels_start[which.min(abs(lat_dist))] 
lat_pixels_end[which.min(abs(lat_dist))]
```

So BDFFP is in pixel [268, 83]

## Bounding box method

Find the pixel that encompass the center of BDFFP and get an area 3x3 around it (i.e. with BDFFP in the center pixel)

```{r paged.print=FALSE}
lat_cen <- which.min(abs(lat_dist))
lon_cen <- which.min(abs(lon_dist))

d = st_dimensions(x)
offset = c(d[["x"]]$offset, d[["y"]]$offset)
res = c(d[["x"]]$delta, d[["y"]]$delta)

# Convert to degrees using this formula
offset[1] + lon_cen * res[1]
offset[2] + lat_cen * res[2]


bb <- st_bbox(c( #I did this sort of by trial and error.  I don't really understand.
  xmin = offset[1] + (lon_cen-2) * res[1],
	ymin = offset[2] + (lat_cen+1) * res[2],
	xmax = offset[1] + (lon_cen+1) * res[1],
	ymax = offset[2] + (lat_cen-2) * res[2]
  ), crs = st_crs(x))
bb
```

## Plot bounding box

```{r}
x_slice <- slice(x, index = 1, along = time) #take just first year

brazil <- 
  raster::getData("GADM", country = "BRA", level = 1, path = here("cache_data")) %>%
  st_as_sf() #get brazil borders

amazonas <- 
  brazil %>%
  filter(NAME_1 == "Amazonas") #the state BDFFP is in

#crop my raster to just what's in Amazonas, Brazil
x_brazil <- 
  st_crop(x_slice, amazonas) %>%
  st_as_stars()
```

There's those GDAL warnings again.

```{r}
p <- 
  ggplot() +
  geom_stars(data = x_brazil) +
  geom_sf(data = st_as_sfc(bb), fill = NA, color = "red") +
  annotate(
    geom = "point",
    x = 360-59.8333,
    y = -2.41,
    shape = "x",
    size = 3,
    color = "red"
  ) +
  # geom_sf(data = amazonas) + #doesn't work because different coordinate systems I think
  coord_sf()
p
```

So bounding box looks right!  The x-axis doesn't show up because `coord_sf()` is not expecting 0--360º, I think.

There are two ways to use this bounding box, I think.

1. Just crop the pixels, then convert to tibble and aggregate using familiar tidyverse methods:

```{r}
library(tictoc) #for benchmarking, run entire chunk from tic() to toc() to get time.
tic()
x_cropped <- x[bb]
x_tbl <- x_cropped %>%
  st_as_stars() %>%  #converts to in RAM object
  as_tibble() %>% #converts to tibble
  group_by(time) %>%  #for each time step
  summarize(across(c(hfls, hfss, pr, tas, tasmax, tasmin), mean))
toc()
head(x_tbl)
```

Quite slow, but transparent.

2. Use the `aggregate()` function from `stars` to take a mean, spatially.

```{r}
tic()
x_tbl2 <- 
  aggregate(x, st_as_sfc(bb), FUN = mean, join = st_intersects) %>%
  as_tibble()
toc()
head(x_tbl2)
```

About twice as fast. Doesn't keep units like the cropping method.

```{r}
p + 
  geom_sf(data = st_as_sfc(x_cropped, as_points = TRUE), fill = NA, color = "green") +
  geom_sf(data = x_tbl2, aes(geometry = geometry), fill = NA, color = "purple")
```

x marks the rough center of BDFFP, green dots mark the pixels selected by cropping with `[` and the purple box marks the area that `aggregate()` averaged over.


```{r}
all.equal(as.numeric(x_tbl$hfls), x_tbl2$hfls)
```

Both methods calculate the same data, so that's good.


# With data across multiple files

I think I need to read in each variable separately, then aggregate stars objects to create separate attributes for each variable.

```{r}
idx <- read_csv(here("data_raw", "metadata", "idx_ssp126.csv"))
EC_earth_files <- 
  idx %>% 
  filter(source_id == "EC-Earth3") %>% 
  group_by(variable_id) %>% 
  select(download_path) %>% 
  group_split()

EC_stars_list <- 
  EC_earth_files %>% 
  map(~{
    read_stars(.x$download_path) %>% set_names(.x$variable_id[1])
  })
EC_stars <- do.call(c, EC_stars_list)
```

This pattern should work for models with fewer files too, so this should be the function to write.

